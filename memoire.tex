\documentclass[a4paper, 12pt]{book}
\usepackage{graphicx}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage[T1]{fontenc}
\usepackage{multirow}

\usepackage[table]{xcolor}

\usepackage{listings}
\usepackage{float}
\usepackage{url}
\usepackage[french]{algorithm}
\usepackage{style/myalgorithm}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{biblatex}
\addbibresource{memoire}
\newcommand{\fBm}{\emph{fBm}~}
\newcommand{\etal}{\emph{et al.}~}
\newcommand{\glAd}{\emph{GL4D}~}
\newcommand{\apiopengl}{API OpenGL\textsuperscript{\textregistered}~}
\newcommand{\opengl}{OpenGL\textsuperscript{\textregistered}~}
\newcommand{\opengles}{OpenGL\textsuperscript{\textregistered}ES~}
\newcommand{\clang}{langage \texttt{C}}
\newcommand{\codesource}{\textsc{Code source}~}
\floatstyle{ruled}
\newfloat{programslist}{htbp}{locs}
\newcommand{\listofprograms}{\listof{programslist}{Liste des codes source}}
\newcounter{program}[subsection]
\renewcommand{\theprogram}{\arabic{chapter}.\arabic{program}}

\newenvironment{program}[1]{
  \if\relax\detokenize{#1}\relax
  \gdef\mycaption{\relax}
  \else
  \gdef\mycaption{#1}
  \fi
  \refstepcounter{program}
  \addcontentsline{locs}{section}{#1}
  \footnotesize
}{
  \begin{description}
    \item[\codesource \theprogram]--~\mycaption
  \end{description}
}

\begin{document}
\begin{titlepage}
  \begin{center}
    %\begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}r}
      \includegraphics[height=2.5cm, width=6cm]{images/paris8Logo.png}
    %\end{tabular*}
    \small 
    \rule{\textwidth}{.5pt}~\\
    \large 
    \textsc{Université Paris 8 - Vincennes à Saint-Denis}\vspace{0.5cm}\\
    \textbf{Master 1 Informatique}\vspace{3.0cm}\\
    \Large
    \textbf{Mémoire projet tuteuré}\\
    \textbf{Qualification de caméras RGB-D}\vspace{1.5cm}\\
    
    \large
    \textbf{Yasmine BOUDJEMAÏ}\\
\textbf{Mélanie DE JESUS CORREIA}\vspace{1.5cm}\\
  \end{center}\vspace{3.5cm}~\\
  \begin{tabular}{ll}
    \hspace{-0.45cm}Organisme~:~&~Université Paris 8 Vincennes-Saint-Denis\\
    \hspace{-0.45cm}Tuteur~:~&~Farès  \textsc{BELHADJ}\\
  \end{tabular}
\end{titlepage}
\frontmatter



\chapter*{Dédicaces}
\markboth{\sc Dédicaces}{}


\chapter*{Remerciements}
\markboth{\sc Remerciements}{}

\chapter*{Résumé}
\markboth{\sc Résumé}{}


%% Table des matières
\tableofcontents
%% La liste des figure est optionnelle (si votre rapport manque de
%% contenu ajouter ce type de pages sera perçu négativement)
\listoffigures
%% La liste des programmes est optionnelle (si votre rapport manque de
%% contenu ajouter ce type de pages sera perçu négativement)
%\listofprogram
\mainmatter
\chapter*{Introduction}
\markboth{\sc Introduction}{}
\addcontentsline{toc}{chapter}{Introduction}
Introduction a faire à la fin.
\chapter{État de l'art}

Dans ce chapitre, nous allons définir ce qu'est une caméra RGB-D, nous énumérons certains des différents modèles existants, nous abordons brièvement les différentes techniques utilisées pour la récupération de la profondeur par une caméra. Enfin, nous discutons les différences recensées sur la \texttt{kinect V2} et \texttt{V3}.

\section{Description d'une caméra RGB-D}

La caméra RGB-D, aussi appelée capteur RGB-D, est une caméra fournissant en même temps une image couleur et une carte de profondeur caractérisant la distance des objets vus dans l'image. Cela est rendu possible grâce à un capteur RGB et un capteur de profondeur (D pour Depth). C'est principalement ces captures qui vont nous intéresser tout au lond des qualifications.


\section{Modèles existants}
Il existe différents modèles de caméras RGB-D. Parmi elles, nous pouvons citer la Kinect et ses différentes versions, Asus Xtion Pro Live, BlasterX Senz3D, Orbbec, Intel RealSens D415, ...
\par \texttt{La Kinect} a fait son apparition en septembre 2008. Elle a été conçue par Microsoft et était destinée pour la console de jeu XBox 360. Elle permettait aux utilisateurs d'interagir avec la console à l'aide d'une NUI \footnote{Natural User Interface (Interface Utilisateur Naturelle), se réfère à une interface utilisateur invisible.} en utilisant les mouvements gestuels et une reconnaissance vocale. Elle sera plus tard utilisée dans les domaines de la  recherche et du développement pour différents secteurs comme le domaine de la médecine, l'industrie automobile, la robotique, l'éducation,  .... 
\par \texttt{Asus Xtion Pro Live} est le modèle de référence que nous utilisons afin d'effectuer les qualifications. Elle utilise la technologie PrimeSense  \footnote{Connu principalement pour sa licence de conception matérielle et de puce employée dans le mécanisme de détection de mouvements de la Kinect XBox360. Pour plus d'informations, le lecteur peut se référer à ce lien \url{https://www.crunchbase.com/organization/primesense#section-web-traffic-by-similarweb}.} pour la détection de mouvements.
\par \texttt{BlasterX Senz3D} a fait son apparation en Septembre 2016. Conçue par Creative,  elle a été présentée comme une webcam intelligente basée sur ce qu'il y a de mieux en matière de savoir-faire et de technologie. Elle possède trois lentilles pour capturer les données visuelles: une caméra RVB, une caméra infra-rouge et un projecteur laser. Ces dernières collaborent avec la technologies Inetl RealSense pour réagir aux expressions faciales et aux gestes corporels des utilisateurs.
\par \texttt{Orbbec Astra Pro} fait partie de la série Astra. Elles offres une vision par ordinateur qui permet des dizaines de fonctions telles que la reconnaissance des visages, la reconnaissance des gestes, le suivi du corps humain, la mesure tridimensionnelle, la perception de l'environnement et la reconstruction de cartes en trois dimensions.  De plus, elles offres une réactivité haut de gamme, une mesure de la profondeur, des dégradés fluides et des contours précis, ainsi que la possibilité de filtrer les pixels de profondeur de faible qualité.
\par \texttt{Intel RealSense D415} a un champ de vision standard bien adapté aux applications de haute précision telles que la numérisation 3D. Elle comprend le processeur Intel RealSense Vision D4 offrant une résolution en profondeur élevée, des capacités de longue portée, une technologie d'obturation globale et un large champ de vision. Grâce à ces deux derniers, la caméra offre une perception précise de la profondeur lorsque l'objet est en mouvement ou que l'appareil est en marche. De plus, elle couvre un champ de vision plus large, minimisant ainsi les angles morts.

\section{Taux d'erreur (RMSE)}

\section{Théoriquement (RMSE)}

\chapter[Modèle logiciel pour la qualification]{Modèle logiciel pour la qualification de caméra RGB-D}
Dans ce passage, nous allons décrire notre outil conçu pour qualifier les caméras.

\section{Description de l'application}

\subsection{Première partie: Affichage de la scène captée }

\subsection{Seconde partie: Interface graphique}



\chapter{Cas pratiques de qualification}

\section{Conception du modèle réel et du modèle virtuel}
\subsection{Conception du modèle réel}
Pour fabriquer le modèle réel, nous avons décidé d'opter pour le polystyrène pour les composants du modèle et du carton pour sa base. Cette dernière sera par la suite recouverte de papier blanc. Les composants seront peints de couleurs distinctes suivant leur hauteur (les éléments qui possèdent une même hauteur seront peints de la même couleur plus particulièrement les rebords du modèle) sauf les demi-sphères et "pyramides".
\par Nous avons opté pour le polystyrène car c'est un matériau facilement maniable et que l'on peut trouver assez facilement.
\subsection{Conception du modèle virtuel}
La réalisation du modèle virtuel s'est faite à l'aide du logiciel 123D Design qui est assez facile d'utilisation. Chaque élément du modèle est conçu en fonction des vraies mesures faites sur le modèle réel.


\section{Preuve de concept (Proof of concept - POC)}
Dans cette section, nous montrons comment nous avons fait pour configurer la caméra \texttt{Asus Xtion Pro Live} afin que le programme puisse effectuer les tests avec cette dernière.
Tout d'abord, nous avons édité le fichier \emph{infoCameras.txt} cité dans le chapitre précédent afin de pouvoir y ajouter les informations relatives à cette caméra.
\par Par la suite, nous n'avons pas eu besoin de rajouter des lignes de code pour la reconnaissance de la caméra (initialisation et récupération de la carte de couleurs et de la carte de profondeurs) car ce modèle de caméra est supporté par la bibliothèque OpenNI2.
\par Enfin, il nous suffira de sélectionner, à partir de l'interface de l'application, le modèle du capteur branché et cocher sur les cases \emph{Detect the model} pour une détection du modèle-étalon et \emph{Do the simple measures} pour démarrer les tests de mesures et rédiger le rapport comme expliqué précédemment. 


\section{Résultats et critique}
\subsection{Résultats obtenus}
Ces résultats sont extraits du rapport rédigé par le programme après réalisation des tests avec la caméra Asus Xtion Pro Live avec une distance de 1.936m (distance entre la caméra et le modèle). Nous avons créé la base de données d'images templates suivant cette distance.  \\ \\

\begin{table}[H]
\begin{tabular}{c|llll}
\cline{1-4}
\multicolumn{1}{|l|}{\textbf{object}}   & \multicolumn{1}{l|}{\textbf{RMSE}} & \multicolumn{1}{l|}{\textbf{Bias}} & \multicolumn{1}{l|}{\textbf{MAPE}} &  \\
\cline{1-4}
\multicolumn{1}{|l|}{Whole model}  & \multicolumn{1}{l|}{0.645805}  & \multicolumn{1}{l|}{0.464625}  & \multicolumn{1}{l|}{0.445257}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Blue piece}  & \multicolumn{1}{l|}{0.163108}  & \multicolumn{1}{l|}{0.0310855}  & \multicolumn{1}{l|}{0.0294527}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Black piece}  & \multicolumn{1}{l|}{0.140734}  & \multicolumn{1}{l|}{0.0231826}  & \multicolumn{1}{l|}{0.0215494}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Vertical magenta piece}  & \multicolumn{1}{l|}{0.301483}  & \multicolumn{1}{l|}{0.130255}  & \multicolumn{1}{l|}{-0.130255}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Yellow piece 1}  & \multicolumn{1}{l|}{0.132736}  & \multicolumn{1}{l|}{0.019909}  & \multicolumn{1}{l|}{0.018747}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Yellow piece 2}  & \multicolumn{1}{l|}{0.122078}  & \multicolumn{1}{l|}{0.0168138}  & \multicolumn{1}{l|}{0.0156804}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Yellow half-sphere}  & \multicolumn{1}{l|}{0.12617}  & \multicolumn{1}{l|}{0.0215568}  & \multicolumn{1}{l|}{-0.0215568}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Magenta pyramid}  & \multicolumn{1}{l|}{0.12583}  & \multicolumn{1}{l|}{0.0232983}  & \multicolumn{1}{l|}{-0.0232983}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Blue pyramid}  & \multicolumn{1}{l|}{0.136497}  & \multicolumn{1}{l|}{0.0254308}  & \multicolumn{1}{l|}{-0.0254308}  &  \\ 
\cline{1-4}
\multicolumn{1}{|l|}{Blue  half-sphere}  & \multicolumn{1}{l|}{0.110225}  & \multicolumn{1}{l|}{0.0178525}  & \multicolumn{1}{l|}{-0.0178525}  &  \\ 
\cline{1-4}
\end{tabular}
\end{table}

\vspace{2cm}

Ci-dessous le tableau résumant le taux d'erreur approximatif obtenu sur des distances différentes, et ce, en  prenant en considération que la valeur RMSE  calculée. \\



\begin{table}[H]
\centering
\setlength\tabcolsep{2pt}
\begin{tabular}{c|lllllllll}
\cline{1-9}
\multicolumn{1}{|l|}{}   & 
\multicolumn{8}{l|}{\textbf{\hspace{4.5cm} Distances (m)}}    \\
\cline{1-9}
\multicolumn{1}{|l|}{\textbf{object}}   & 
\multicolumn{1}{l|}{\textbf{1.936 }} & 
\multicolumn{1}{l|}{\textbf{1.843}} & 
\multicolumn{1}{l|}{\textbf{1.748}} &  
\multicolumn{1}{l|}{\textbf{1.639 }} & 
\multicolumn{1}{l|}{\textbf{1.550}} & 
\multicolumn{1}{l|}{\textbf{1.445}} & 
\multicolumn{1}{l|}{\textbf{1.359}} & 
\multicolumn{1}{l|}{\textbf{1.259}} & \\
\cline{1-9}
\multicolumn{1}{|l|}{Whole model}  & 
\multicolumn{1}{l|}{65\%}  &  
\multicolumn{1}{l|}{69\%}  & 
\multicolumn{1}{l|}{71\%}  & 
\multicolumn{1}{l|}{76\%}  & 
\multicolumn{1}{l|}{80\%}  & 
\multicolumn{1}{l|}{84\%}  & 
\multicolumn{1}{l|}{89\%}  & 
\multicolumn{1}{l|}{94\%}  &  \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Blue piece}  &
\multicolumn{1}{l|}{16\%}  &
\multicolumn{1}{l|}{17\%}  & 
\multicolumn{1}{l|}{17\%} & 
\multicolumn{1}{l|}{18\%}  & 
\multicolumn{1}{l|}{18\%}  &  
\multicolumn{1}{l|}{21\%}  & 
\multicolumn{1}{l|}{21\%}  &
\multicolumn{1}{l|}{22\%}   &  \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Black piece}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{15\%}  & 
\multicolumn{1}{l|}{15\%} & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{17\%}  &
\multicolumn{1}{l|}{16\%}  & 
\multicolumn{1}{l|}{18\%}  & 
\multicolumn{1}{l|}{18\%}  &  \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Vertical magenta piece}  & 
\multicolumn{1}{l|}{30\%}  & 
\multicolumn{1}{l|}{30\%}  & 
\multicolumn{1}{l|}{30\%} & 
\multicolumn{1}{l|}{31\%}  & 
\multicolumn{1}{l|}{31\%}  & 
\multicolumn{1}{l|}{31\%}  & 
\multicolumn{1}{l|}{32\%}  &  
\multicolumn{1}{l|}{38\%}  & \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Yellow piece 1}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Yellow piece 2}  & 
\multicolumn{1}{l|}{12\%}  & 
\multicolumn{1}{l|}{12\%}  & 
\multicolumn{1}{l|}{12\%}  &  
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{12\%}  & 
\multicolumn{1}{l|}{15\%}  & \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Yellow half-sphere}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{12\%}  & 
\multicolumn{1}{l|}{12\%}  &  
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{15\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{15\%}  & 
\\ 
\cline{1-9}
\multicolumn{1}{|l|}{Magenta pyramid}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{14\%}  &  
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{15\%}  & 
\multicolumn{1}{l|}{16\%}  & 
\multicolumn{1}{l|}{16\%}  & \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Blue pyramid}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{13\%}  &  
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{16\%}  & 
\multicolumn{1}{l|}{16\%}  & 
\multicolumn{1}{l|}{17\%}  & \\ 
\cline{1-9}
\multicolumn{1}{|l|}{Blue  half-sphere}  & 
\multicolumn{1}{l|}{11\%}  & 
\multicolumn{1}{l|}{11\%}  & 
\multicolumn{1}{l|}{12\%}  &  
\multicolumn{1}{l|}{12\%}  & 
\multicolumn{1}{l|}{13\%}  & 
\multicolumn{1}{l|}{14\%}  & 
\multicolumn{1}{l|}{15\%}  & 
\multicolumn{1}{l|}{14\%}  & \\ 
\cline{1-9}
\multicolumn{1}{|l|}{\textbf{Average rate}} & 
\multicolumn{1}{l|}{\textbf{20.1\%}}  & 
\multicolumn{1}{l|}{\textbf{20.7\%}}  &  
\multicolumn{1}{l|}{\textbf{20.9\%}}  & 
\multicolumn{1}{l|}{\textbf{21.8\%}}  & 
\multicolumn{1}{l|}{\textbf{22.8\%}}  & 
\multicolumn{1}{l|}{\textbf{23.8\%}}  & 
\multicolumn{1}{l|}{\textbf{24.5\%}}  &  
\multicolumn{1}{l|}{\textbf{26.2\%}}  &\\ 
\cline{1-9}

\end{tabular}
\end{table}

\vspace{2cm} 
\par On peut observer aisément un taux d'erreur de plus en plus élevé pour le modèle en entier. Pour les autres éléments, le taux reste pratiquement constant. 

\subsection{Critiques}
Comme nous doutons de la méthode employée pour extraire les données OpenGL correspondantes aux données de la depth de la caméra (données extraites aux mêmes pixels), nous pensons qu'il est tout à fait normal que le taux soit si élevé. Toutefois, comme après chaque changement de distance (ie: la caméra se rapproche du modèle observé), le modèle 3D subit un changement d'échelle afin qu'il soit superposé au modèle réel. Ainsi, la valeur de la coordonnée $z$ de chaque pixel du modèle 3D subit pareillement ce changement (devient de plus en plus grande).



\chapter{Conclusion et Perspectives\label{chap-conclusion}}


\nocite{*}
%	\bibliographystyle{alpha}
%\bibliography{memoire}
\printbibliography
\end{document}

